# Comparing `tmp/ScreenPro2-0.3.1-py2.py3-none-any.whl.zip` & `tmp/ScreenPro2-0.3.2-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 29459 bytes, number of entries: 22
--rw-r--r--  2.0 unx      292 b- defN 24-May-12 03:11 screenpro/__init__.py
--rw-r--r--  2.0 unx       31 b- defN 24-May-12 03:11 screenpro/__main__.py
--rw-r--r--  2.0 unx     8370 b- defN 24-May-12 03:11 screenpro/assays.py
--rw-r--r--  2.0 unx     7406 b- defN 24-May-12 03:11 screenpro/load.py
--rw-r--r--  2.0 unx     5343 b- defN 24-May-12 03:11 screenpro/main.py
--rw-r--r--  2.0 unx    16261 b- defN 24-May-12 03:11 screenpro/phenoscore.py
--rw-r--r--  2.0 unx     1694 b- defN 24-May-12 03:11 screenpro/phenostat.py
--rw-r--r--  2.0 unx     7040 b- defN 24-May-12 03:11 screenpro/plotting.py
--rw-r--r--  2.0 unx     3179 b- defN 24-May-12 03:11 screenpro/utils.py
--rw-r--r--  2.0 unx     1731 b- defN 24-May-12 03:11 screenpro/ngs/__init__.py
--rw-r--r--  2.0 unx     6944 b- defN 24-May-12 03:11 screenpro/ngs/cas12.py
--rw-r--r--  2.0 unx     6808 b- defN 24-May-12 03:11 screenpro/ngs/cas9.py
--rw-r--r--  2.0 unx    14980 b- defN 24-May-12 03:11 screenpro/ngs/counter.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-12 03:11 screenpro/tests/__init__.py
--rw-r--r--  2.0 unx      821 b- defN 24-May-12 03:11 screenpro/tests/test_fastq2count.py
--rw-r--r--  2.0 unx     1791 b- defN 24-May-12 03:11 screenpro/tests/test_phenoscore.py
--rw-r--r--  2.0 unx     1187 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/LICENSE
--rw-r--r--  2.0 unx    13013 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       50 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1775 b- defN 24-May-12 03:14 ScreenPro2-0.3.1.dist-info/RECORD
-22 files, 98836 bytes uncompressed, 26597 bytes compressed:  73.1%
+Zip file size: 29703 bytes, number of entries: 22
+-rw-r--r--  2.0 unx      292 b- defN 24-May-19 21:52 screenpro/__init__.py
+-rw-r--r--  2.0 unx       31 b- defN 24-May-19 21:52 screenpro/__main__.py
+-rw-r--r--  2.0 unx     9351 b- defN 24-May-19 21:52 screenpro/assays.py
+-rw-r--r--  2.0 unx     7406 b- defN 24-May-19 21:52 screenpro/load.py
+-rw-r--r--  2.0 unx     5343 b- defN 24-May-19 21:52 screenpro/main.py
+-rw-r--r--  2.0 unx    16444 b- defN 24-May-19 21:52 screenpro/phenoscore.py
+-rw-r--r--  2.0 unx     1833 b- defN 24-May-19 21:52 screenpro/phenostat.py
+-rw-r--r--  2.0 unx     7040 b- defN 24-May-19 21:52 screenpro/plotting.py
+-rw-r--r--  2.0 unx     3173 b- defN 24-May-19 21:52 screenpro/utils.py
+-rw-r--r--  2.0 unx     1731 b- defN 24-May-19 21:52 screenpro/ngs/__init__.py
+-rw-r--r--  2.0 unx     6944 b- defN 24-May-19 21:52 screenpro/ngs/cas12.py
+-rw-r--r--  2.0 unx     6808 b- defN 24-May-19 21:52 screenpro/ngs/cas9.py
+-rw-r--r--  2.0 unx    15424 b- defN 24-May-19 21:52 screenpro/ngs/counter.py
+-rw-r--r--  2.0 unx        0 b- defN 24-May-19 21:52 screenpro/tests/__init__.py
+-rw-r--r--  2.0 unx      821 b- defN 24-May-19 21:52 screenpro/tests/test_fastq2count.py
+-rw-r--r--  2.0 unx     1791 b- defN 24-May-19 21:52 screenpro/tests/test_phenoscore.py
+-rw-r--r--  2.0 unx     1187 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx    13013 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx       50 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1775 b- defN 24-May-19 21:56 ScreenPro2-0.3.2.dist-info/RECORD
+22 files, 100577 bytes uncompressed, 26841 bytes compressed:  73.3%
```

## zipnote {}

```diff
@@ -42,26 +42,26 @@
 
 Filename: screenpro/tests/test_fastq2count.py
 Comment: 
 
 Filename: screenpro/tests/test_phenoscore.py
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/LICENSE
+Filename: ScreenPro2-0.3.2.dist-info/LICENSE
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/METADATA
+Filename: ScreenPro2-0.3.2.dist-info/METADATA
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/WHEEL
+Filename: ScreenPro2-0.3.2.dist-info/WHEEL
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/entry_points.txt
+Filename: ScreenPro2-0.3.2.dist-info/entry_points.txt
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/top_level.txt
+Filename: ScreenPro2-0.3.2.dist-info/top_level.txt
 Comment: 
 
-Filename: ScreenPro2-0.3.1.dist-info/RECORD
+Filename: ScreenPro2-0.3.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## screenpro/__init__.py

```diff
@@ -2,10 +2,10 @@
 from . import phenoscore as ps
 from . import utils
 from . import ngs
 from . import load
 from .ngs import Counter
 from .assays import PooledScreens, GImaps
 
-__version__ = "0.3.1"
+__version__ = "0.3.2"
 __author__ = "Abe Arab"
 __email__ = 'abea@arcinstitute.org' # "abarbiology@gmail.com"
```

## screenpro/assays.py

```diff
@@ -1,35 +1,37 @@
 """
 Assays module
 """
 
 import numpy as np
 import pandas as pd
 import anndata as ad
+import scanpy as sc
 
+from pydeseq2 import preprocessing
 from .phenoscore import runPhenoScore, runPhenoScoreForReplicate
 from .utils import ann_score_df
 from copy import copy
 
 
 class PooledScreens(object):
     """
     pooledScreens class for processing CRISPR screen datasets
     """
 
-    def __init__(self, adata, transformation='log2(x+1)', test='ttest', n_reps=3):
+    def __init__(self, adata, fc_transformation='log2(x+1)', test='ttest', n_reps=3):
         """
         Args:
             adata (AnnData): AnnData object with adata.X as a matrix of sgRNA counts
-            transformation (str): transformation to apply to the data before calculating phenotype scores
+            fc_transformation (str): fold change transformation to apply for calculating phenotype scores
             test (str): statistical test to use for calculating phenotype scores
         """
         self.adata = adata
         self.pdata = None
-        self.transformation = transformation
+        self.fc_transformation = fc_transformation
         self.test = test
         self.n_reps = n_reps
         self.phenotypes = {}
         self.phenotype_names = []
 
     # def __repr__(self):
     #     descriptions = ''
@@ -37,15 +39,15 @@
     #         scores = "', '".join(self.phenotypes[score_level].columns.get_level_values(0).unique().to_list())
     #         descriptions += f"Phenotypes in score_level = '{score_level}':\n    scores: '{scores}'\n"
 
     #     return f'obs->samples\nvar->elementss\n\n{self.__repr__()}\n\n{descriptions}'
 
     def copy(self):
         return copy(self)
-
+    
     def _add_phenotype_results(self, phenotype_name):
         if phenotype_name in self.phenotype_names:
             raise ValueError(f"Phenotype '{phenotype_name}' already exists in self.phenotype_names!")
         self.phenotype_names.append(phenotype_name)
 
     def _calculateGrowthFactor(self, untreated, treated, db_rate_col):
         """
@@ -71,45 +73,62 @@
             growth_factors.append(('rho', np.abs(db_untreated - db_treated), replicate, f'rho_replicate_{replicate}'))
 
         out = pd.DataFrame(growth_factors, columns=['score', 'growth_factor', 'replicate', 'index']).set_index('index')
         out.index.name = None
 
         return out
 
-    def calculateDrugScreen(self, t0, untreated, treated, db_untreated, db_treated, score_level, db_rate_col='pop_doublings', run_name=None):
+    def countNormalization(self):
+        """
+        Normalize the counts data in adata.X
+        """
+        self.adata.layers['raw_counts'] = self.adata.X.copy()
+        
+        # normalize counts by sequencing depth
+        norm_counts, size_factors = preprocessing.deseq2_norm(self.adata.X)
+        # update adata object
+        self.adata.obs['size_factors'] = size_factors
+        self.adata.layers['seq_depth_norm'] = norm_counts
+        self.adata.X = self.adata.layers['seq_depth_norm']
+    
+    def calculateDrugScreen(self, t0, untreated, treated, db_untreated, db_treated, score_level, db_rate_col='pop_doublings', run_name=None, **kwargs):
         """
         Calculate `gamma`, `rho`, and `tau` phenotype scores for a drug screen dataset in a given `score_level`.
         To normalize by growth rate, the doubling rate of the untreated and treated conditions are required.
 
         Args:
             t0 (str): name of the untreated condition
             untreated (str): name of the untreated condition
             treated (str): name of the treated condition
             db_untreated (float): doubling rate of the untreated condition
             db_treated (float): doubling rate of the treated condition
             score_level (str): name of the score level
             db_rate_col (str): column name for the doubling rate, default is 'pop_doublings'
             run_name (str): name for the phenotype calculation run
+            **kwargs: additional arguments to pass to runPhenoScore
         """
         # calculate phenotype scores: gamma, tau, rho
         gamma_name, gamma = runPhenoScore(
             self.adata, cond1=t0, cond2=untreated, growth_rate=db_untreated,
             n_reps=self.n_reps,
-            transformation=self.transformation, test=self.test, score_level=score_level
+            transformation=self.fc_transformation, test=self.test, score_level=score_level,
+            **kwargs
         )
         tau_name, tau = runPhenoScore(
             self.adata, cond1=t0, cond2=treated, growth_rate=db_treated,
             n_reps=self.n_reps,
-            transformation=self.transformation, test=self.test, score_level=score_level
+            transformation=self.fc_transformation, test=self.test, score_level=score_level,
+            **kwargs
         )
         # TO-DO: warning / error if db_untreated and db_treated are too close, i.e. growth_rate ~= 0.
         rho_name, rho = runPhenoScore(
             self.adata, cond1=untreated, cond2=treated, growth_rate=np.abs(db_untreated - db_treated),
             n_reps=self.n_reps,
-            transformation=self.transformation, test=self.test, score_level=score_level
+            transformation=self.fc_transformation, test=self.test, score_level=score_level,
+            **kwargs
         )
 
         if not run_name: run_name = score_level
         # save all results into a multi-index dataframe
         self.phenotypes[run_name] = pd.concat({
             f'gamma:{gamma_name}': gamma, f'tau:{tau_name}': tau, f'rho:{rho_name}': rho
         }, axis=1)
@@ -121,39 +140,49 @@
 
         growth_factor_table = self._calculateGrowthFactor(
             untreated = untreated, treated = treated, db_rate_col = db_rate_col
         )
 
         # get replicate level phenotype scores
         pdata_df = pd.concat([
-            runPhenoScoreForReplicate(self,'T0', untreated,'gamma',growth_factor_table).add_prefix('gamma_'),
-            runPhenoScoreForReplicate(self,'T0', treated,'tau',growth_factor_table).add_prefix('tau_'),
-            runPhenoScoreForReplicate(self ,untreated,treated,'rho',growth_factor_table).add_prefix('rho_')
+            runPhenoScoreForReplicate(
+                self.adata, x_label = x_label, y_label = y_label, score = score_label,
+                transformation=self.fc_transformation, 
+                growth_factor_table=growth_factor_table
+            ).add_prefix(f'{score_label}_')
+
+            for x_label, y_label, score_label in [
+                ('T0', untreated, 'gamma'),
+                ('T0', treated, 'tau'),
+                (untreated, treated, 'rho')
+            ]
         ],axis=1).T
         # add .pdata
         self.pdata = ad.AnnData(
             X = pdata_df,
             obs = growth_factor_table.loc[pdata_df.index,:],
             var=self.adata.var
         )
         
-    def calculateFlowBasedScreen(self, low_bin, high_bin, score_level, run_name=None):
+    def calculateFlowBasedScreen(self, low_bin, high_bin, score_level, run_name=None, **kwargs):
         """
         Calculate phenotype scores for a flow-based screen dataset.
 
         Args:
             low_bin (str): name of the low bin condition
             high_bin (str): name of the high bin condition
             score_level (str): name of the score level
             run_name (str): name for the phenotype calculation run
+            **kwargs: additional arguments to pass to runPhenoScore
         """
         # calculate phenotype scores
         delta_name, delta = runPhenoScore(
             self.adata, cond1=low_bin, cond2=high_bin, n_reps=self.n_reps,
-            transformation=self.transformation, test=self.test, score_level=score_level
+            transformation=self.fc_transformation, test=self.test, score_level=score_level,
+            **kwargs
         )
 
         if not run_name: run_name = score_level
         # save all results into a multi-index dataframe
         self.phenotypes[run_name] = pd.concat({
             f'delta:{delta_name}': delta
         }, axis=1)
```

## screenpro/phenoscore.py

```diff
@@ -1,16 +1,15 @@
 """
 phenoscore module
 """
 
 import numpy as np
+import anndata as ad
 import pandas as pd
-from pydeseq2 import preprocessing
 from .phenostat import matrixStat, getFDR
-from .utils import find_low_counts
 
 
 def calculateDelta(x, y, transformation, level):
     """Calculate log ratio of y / x.
     `level` == 'all' (i.e. averaged across all values, sgRNA library elements and replicates)
     `level` == 'col' (i.e. averaged across columns, replicates)
 
@@ -20,36 +19,42 @@
         transformation (str): transformation to use for calculating score
         level (str): level to use for calculating score
     
     Returns:
         np.array: array of log ratio values
     """
     # check if transformation is implemented
-    if transformation not in ['log2(x+1)', 'log10', 'log1p']:
+    if transformation not in ['log2', 'log2(x+1)', 'log10', 'log1p']:
         raise ValueError(f'transformation "{transformation}" not recognized')
     
     if level == 'all':
         # average across all values
-        if transformation == 'log2(x+1)':
+        if transformation == 'log2':
+            return np.log2(y) - np.log2(x)
+        elif transformation == 'log2(x+1)':
             return np.mean(np.log2(y+1) - np.log2(x+1))
         elif transformation == 'log10':
             return np.mean(np.log10(y) - np.log10(x))
         elif transformation == 'log1p':
             return np.mean(np.log1p(y) - np.log1p(x))
     elif level == 'row':
         # average across rows
-        if transformation == 'log2(x+1)':
+        if transformation == 'log2':
+            return np.log2(y) - np.log2(x)
+        elif transformation == 'log2(x+1)':
             return np.mean(np.log2(y+1) - np.log2(x+1), axis=0)
         elif transformation == 'log10':
             return np.mean(np.log10(y) - np.log10(x), axis=0)
         elif transformation == 'log1p':
             return np.mean(np.log1p(y) - np.log1p(x), axis=0)
     elif level == 'col':
         # average across columns
-        if transformation == 'log2(x+1)':
+        if transformation == 'log2':
+            return np.mean(np.log2(y) - np.log2(x), axis=1)
+        elif transformation == 'log2(x+1)':
             return np.mean(np.log2(y+1) - np.log2(x+1), axis=1)
         elif transformation == 'log10':
             return np.mean(np.log10(y) - np.log10(x), axis=1)
         elif transformation == 'log1p':
             return np.mean(np.log1p(y) - np.log1p(x), axis=1)
 
 
@@ -104,52 +109,126 @@
 
     # compute p-value
     p_values = matrixStat(x, y, test=test, level = level)
 
     return scores, p_values
 
 
+def generatePseudoGeneAnnData(adata, num_pseudogenes='auto', pseudogene_size='auto', ctrl_label='negCtrl'):
+    """Generate pseudogenes from negative control elements in the library.
+
+    Args:
+        adata (AnnData): AnnData object
+        num_pseudogenes (int): number of pseudogenes to generate
+        pseudogene_size (int): number of sgRNA elements in each pseudogene
+        ctrl_label (str): control label, default is 'negCtrl'
+    
+    Returns:
+        AnnData: AnnData object with pseudogenes
+    """
+    if pseudogene_size == 'auto':
+        # sgRNA elements / target in the library
+        pseudogene_size = int(adata.var[~adata.var.targetType.eq(ctrl_label)].groupby('target').size().mean())
+
+    if num_pseudogenes == 'auto':
+        # approx number of target in the library
+        num_pseudogenes = len(adata.var.loc[~adata.var.targetType.eq(ctrl_label),'target'].unique()) * pseudogene_size
+    
+    adata_ctrl = adata[:,adata.var.targetType.eq(ctrl_label)].copy()
+    ctrl_elements = adata_ctrl.var.index.to_list()
+    
+    adata_pseudo_list = []
+    pseudo_source_sgrna = []
+
+    for pseudo_num in range(0, num_pseudogenes, pseudogene_size):
+        pseudo_elements = np.random.choice(ctrl_elements, pseudogene_size, replace=False)
+        pseudo_labels = [f'pseudo_{pseudo_num}_{i}' for i in range(1,pseudogene_size+1)]
+        
+        adata_pseudo = ad.AnnData(
+            X = adata_ctrl.X[:,adata_ctrl.var.index.isin(pseudo_elements)],
+            obs = adata_ctrl.obs   
+        )
+        adata_pseudo.var_names = pseudo_labels
+        adata_pseudo_list.append(adata_pseudo)
+        
+        for element in pseudo_elements: 
+            pseudo_source_sgrna.append(element)
+        
+    out = ad.concat(adata_pseudo_list, axis=1)
+    out.var['target'] = out.var.index.str.split('_').str[:-1].str.join('_')
+    out.var['targetType'] = ctrl_label
+    out.var['source'] = pseudo_source_sgrna
+    out.obs = adata_ctrl.obs.copy()
+    
+    return out
+
+
+def calculateZScorePhenotypeScore(score_df,ctrl_label='negCtrl'):
+    """Calculate z-score normalized phenotype score.
+    
+    Args:
+        score_df (pd.DataFrame): dataframe of scores that includes `score` and `targetType` columns
+        ctrl_label (str): control label, default is 'negCtrl'
+    
+    Returns:
+        pd.Series: z-score normalized phenotype score
+    """
+    # calculate control median and std
+    ctrl_std = score_df[score_df.targetType.eq(ctrl_label)].score.std()
+    # z-score normalization
+    out = score_df.score / ctrl_std
+
+    return out
+
+
 def runPhenoScore(adata, cond1, cond2, transformation, score_level, test,
-                  growth_rate=1, n_reps=2, keep_top_n = None,num_pseudogenes=None,
-                  get_z_score=False,ctrl_label='negCtrl'):
+                  growth_rate=1, n_reps=2, keep_top_n = None,num_pseudogenes='auto', pseudogene_size='auto',
+                  count_layer=None, get_z_score=False, ctrl_label='negCtrl'):
     """Calculate phenotype score and p-values when comparing `cond2` vs `cond1`.
 
     Args:
         adata (AnnData): AnnData object
         cond1 (str): condition 1
         cond2 (str): condition 2
         transformation (str): transformation to use for calculating score
         test (str): test to use for calculating p-value ('MW': Mann-Whitney U rank; 'ttest' : t-test)
         score_level (str): score level
         growth_rate (int): growth rate
         n_reps (int): number of replicates
+        keep_top_n (int): number of top guides to keep per target
+        num_pseudogenes (int): number of pseudogenes to generate
+        pseudogene_size (int): number of sgRNA elements in each pseudogene
+        count_layer (str): count layer to use for calculating score, default is None (use default count layer in adata.X)
         get_z_score (bool): boolean to calculate z-score normalized phenotype score and add as a new column (default is False)
         ctrl_label (str): control label
     
     Returns:
         str: result name
         pd.DataFrame: result dataframe
     """
     # format result name
     result_name = f'{cond2}_vs_{cond1}'
     print(f'\t{cond2} vs {cond1}')
 
-    count_layer = 'seq_depth_norm'
     # check if count_layer exists
-    if 'seq_depth_norm' not in adata.layers.keys():
-        seqDepthNormalization(adata)
+    if count_layer is None:
+        pass
+    elif count_layer not in adata.layers.keys():
+        raise ValueError(f"Layer '{count_layer}' not found in adata.layers.keys().")
+    elif count_layer in adata.layers.keys():
+        adata.X = adata.layers[count_layer].copy()
     
     # evaluate library table to get targets and riase error if not present
     required_columns = ['target', 'sequence']
     missing_columns = list(set(required_columns) - set(adata.var.columns))
     if len(missing_columns) > 0:
         raise ValueError(f"Missing required columns in library table: {missing_columns}")
 
     # calc phenotype score and p-value
-    if score_level == 'compare_reps':
+    if score_level in ['compare_reps']:
         # prep counts for phenoScore calculation
         df_cond1 = adata[adata.obs.query(f'condition=="{cond1}"').index[:n_reps],].to_df(count_layer).T
         df_cond2 = adata[adata.obs.query(f'condition=="{cond2}"').index[:n_reps],].to_df(count_layer).T
 
         # convert to numpy arrays
         x = df_cond1.to_numpy()
         y = df_cond2.to_numpy()
@@ -183,153 +262,128 @@
         result[f'{test} pvalue'] = p_values
         result['BH adj_pvalue'] = adj_p_values
     
     elif score_level in ['compare_guides']:
         if n_reps == 2:
             pass
         else:
-            raise ValueError(f'n_reps "{n_reps}" not recognized')
-
-        find_low_counts(adata)
-        adata = adata[:,~adata.var.low_count].copy()
-
-        adata.var.drop(columns='low_count',inplace=True)
-
-        # generate pseudo gene labels
-        generatePseudoGeneLabels(adata, num_pseudogenes=num_pseudogenes, ctrl_label=ctrl_label)
-        # drop categories from target column!
-        adata.var['target'] = adata.var['target'].to_list()
-        # replace values in target columns for negative control with pseudogene label
-        adata.var.loc[
-            adata.var.targetType.eq(ctrl_label), 'target'
-        ] = adata.var.loc[adata.var.targetType.eq(ctrl_label), 'pseudoLabel']
-        # drop pseudoLabel column 
-        adata.var.drop(columns='pseudoLabel', inplace=True)
+            raise ValueError('Currently, only n_reps=2 is supported for score_level="compare_guides"')
+        # keep original adata for later use
+        adata0 = adata.copy()
 
         # prep counts for phenoScore calculation
-        df_cond1 = adata[adata.obs.query(f'condition=="{cond1}"').index].to_df().T
-        df_cond2 = adata[adata.obs.query(f'condition=="{cond2}"').index].to_df().T        # get control values
-
+        df_cond1 = adata0[adata0.obs.query(f'condition=="{cond1}"').index].to_df().T
+        df_cond2 = adata0[adata0.obs.query(f'condition=="{cond2}"').index].to_df().T
         # get control values
-        x_ctrl = df_cond1[adata.var.targetType.eq(ctrl_label)].to_numpy()
-        y_ctrl = df_cond2[adata.var.targetType.eq(ctrl_label)].to_numpy()
+        x_ctrl = df_cond1[adata0.var.targetType.eq(ctrl_label)].to_numpy()
+        y_ctrl = df_cond2[adata0.var.targetType.eq(ctrl_label)].to_numpy()
+        del df_cond1, df_cond2
+        
+        adata_pseudo = generatePseudoGeneAnnData(adata0, num_pseudogenes=num_pseudogenes, pseudogene_size=pseudogene_size, ctrl_label=ctrl_label)
+        adata = ad.concat([adata0[:,~adata0.var.targetType.eq(ctrl_label)], adata_pseudo], axis=1)
+        adata.obs = adata0.obs.copy()
 
+        # prep counts for phenoScore calculation
+        df_cond1 = adata[adata.obs.query(f'condition=="{cond1}"').index].to_df().T
+        df_cond2 = adata[adata.obs.query(f'condition=="{cond2}"').index].to_df().T
+        
         targets = []
         scores = []
         p_values = []
-
+        
         # group by target genes or pseudogenes to aggregate counts for score calculation
         for target_name, target_group in adata.var.groupby('target'):
             # convert to numpy arrays
-            x = df_cond1.loc[target_group.index,:].to_numpy()
-            y = df_cond2.loc[target_group.index,:].to_numpy()
+            x = df_cond1.loc[target_group.index,:]
+            y = df_cond2.loc[target_group.index,:]
             # Sort and find top n guide per target, see #18
             if keep_top_n:
-                x.sort()
-                y.sort()
-                x = x[:keep_top_n]
-                y = y[:keep_top_n]
-            
+                x = x.sort_values(x.columns.to_list(), ascending=False)
+                y = y.sort_values(y.columns.to_list(), ascending=False)
+                x = x.iloc[:keep_top_n, :]
+                y = y.iloc[:keep_top_n, :]
+            # convert to numpy arrays
+            x = x.to_numpy()
+            y = y.to_numpy()
+
             # calculate growth score and p_value
             target_scores, target_p_values = matrixTest(
                 x=x, y=y, x_ctrl=x_ctrl, y_ctrl=y_ctrl,
-                transformation=transformation, level='row', test=test,
+                transformation=transformation, 
+                level='all', # test across all guides and replicates per target
+                test=test,
                 growth_rate=growth_rate
             )
-
+            
             scores.append(target_scores)
             p_values.append(target_p_values)
             targets.append(target_name)
         
         # combine results into a dataframe
-        result = pd.concat({
-            'replicate_1':pd.concat([
-                pd.Series([s1 for s1,_ in scores], index=targets, name='score'),
-                pd.Series([p1 for p1,_ in p_values], index=targets, name=f'{test} pvalue'),
+        result = pd.concat([
+            pd.Series([np.mean(s) for s in scores], index=targets, name='score'),
+            pd.Series([np.mean(p) for p in p_values], index=targets, name=f'{test} pvalue'),
+        ], axis=1)
+
+        # # combine results into a dataframe
+        # result = pd.concat({
+        #     'replicate_1':pd.concat([
+        #         pd.Series([s1 for s1,_ in scores], index=targets, name='score'),
+        #         pd.Series([p1 for p1,_ in p_values], index=targets, name=f'{test} pvalue'),
                 
-            ],axis=1),
-            'replicate_2':pd.concat([
-                pd.Series([s2 for _,s2 in scores], index=targets, name='score'),
-                pd.Series([p2 for _,p2 in p_values], index=targets, name=f'{test} pvalue'),
-            ],axis=1),
-            'replicate_ave':pd.concat([
-                pd.Series([np.mean([s1,s2]) for s1,s2 in scores], index=targets, name='score'),
-                pd.Series([np.mean([p1,p2]) for p1,p2 in p_values], index=targets, name=f'{test} pvalue'),
-            ],axis=1)
-        },axis=1)
+        #     ],axis=1),
+        #     'replicate_2':pd.concat([
+        #         pd.Series([s2 for _,s2 in scores], index=targets, name='score'),
+        #         pd.Series([p2 for _,p2 in p_values], index=targets, name=f'{test} pvalue'),
+        #     ],axis=1),
+        #     'replicate_ave':pd.concat([
+        #         pd.Series([np.mean([s1,s2]) for s1,s2 in scores], index=targets, name='score'),
+        #         pd.Series([np.mean([p1,p2]) for p1,p2 in p_values], index=targets, name=f'{test} pvalue'),
+        #     ],axis=1)
+        # },axis=1)
     
     else:
-        raise ValueError(f'score_level "{score_level}" not recognized')
+        raise ValueError(f'score_level "{score_level}" not recognized. Currently, "compare_reps" and "compare_guides" are supported.')
     
     
     return result_name, result
 
 
-def seqDepthNormalization(adata):
-    """Normalize counts by sequencing depth.
-    
-    Args:
-        adata (AnnData): AnnData object
-    """
-    # normalize counts by sequencing depth
-    norm_counts, size_factors = preprocessing.deseq2_norm(adata.X)
-    # update adata object
-    adata.obs['size_factors'] = size_factors
-    adata.layers['seq_depth_norm'] = norm_counts
-
-
-def calculateZScorePhenotypeScore(score_df,ctrl_label='negCtrl'):
-    """Calculate z-score normalized phenotype score.
-    
-    Args:
-        score_df (pd.DataFrame): dataframe of scores that includes `score` and `targetType` columns
-        ctrl_label (str): control label, default is 'negCtrl'
-    
-    Returns:
-        pd.Series: z-score normalized phenotype score
-    """
-    # calculate control median and std
-    ctrl_std = score_df[score_df.targetType.eq(ctrl_label)].score.std()
-    # z-score normalization
-    out = score_df.score / ctrl_std
-
-    return out
-
-
-def runPhenoScoreForReplicate(screen, x_label, y_label, score, growth_factor_table, get_z_score=False, ctrl_label='negCtrl'):
+def runPhenoScoreForReplicate(adata, x_label, y_label, score, growth_factor_table, transformation, get_z_score=False, ctrl_label='negCtrl'):
     """Calculate phenotype score for each pair of replicates.
 
     Args:
-        screen: ScreenPro object
+        adata (AnnData): AnnData object
         x_label: name of the first condition in column `condition` of `screen.adata.obs`
         y_label: name of the second condition in column `condition` of `screen.adata.obs`
         score: score to use for calculating phenotype score, i.e. 'gamma', 'tau', or 'rho'
         growth_factor_table: dataframe of growth factors, i.e. output from `getGrowthFactors` function
+        transformation (str): transformation to use for calculating score
         get_z_score: boolean to calculate z-score normalized phenotype score instead of regular score (default is False)
         ctrl_label: string to identify labels of negative control elements in sgRNA library (default is 'negCtrl')
 
     Returns:
         pd.DataFrame: dataframe of phenotype scores
     """
-    adat = screen.adata.copy()
+    adat = adata.copy()
 
     adat_ctrl = adat[:, adat.var.targetType.eq(ctrl_label)].copy()
 
     results = {}
 
     for replicate in adat.obs.replicate.unique():
         res = calculatePhenotypeScore(
             x=adat[adat.obs.query(f'condition == "{x_label}" & replicate == {str(replicate)}').index].X,
             y=adat[adat.obs.query(f'condition == "{y_label}" & replicate == {str(replicate)}').index].X,
 
             x_ctrl=adat_ctrl[adat_ctrl.obs.query(f'condition == "{x_label}" & replicate == {str(replicate)}').index].X,
             y_ctrl=adat_ctrl[adat_ctrl.obs.query(f'condition == "{y_label}" & replicate == {str(replicate)}').index].X,
 
             growth_rate=growth_factor_table.query(f'score=="{score}" & replicate=={replicate}')['growth_factor'].values[0],
-            transformation=screen.transformation,
+            transformation=transformation,
             level='row'  # there is only one column so `row` option here is equivalent to the value before averaging.
         )
 
         if get_z_score:
             res = calculateZScorePhenotypeScore(
                 pd.DataFrame({'score':res,'targetType':adat.var.targetType},index=adat.var.index),
                 ctrl_label=ctrl_label
@@ -339,68 +393,7 @@
 
     out = pd.DataFrame(
         results,
         index=adat.var.index
     )
 
     return out
-
-
-def generatePseudoGeneLabels(adata, num_pseudogenes=None, ctrl_label='negCtrl'):
-    """Generate new labels per `num_pseudogenes` randomly selected non-targeting elements in `adata.var`.
-
-    Args:
-        adata (AnnData): AnnData object
-        num_pseudogenes (int): number of pseudogenes
-        ctrl_label (str): control label
-    
-    Returns:
-        None
-    """
-    # check if num_pseudogenes is defined. 
-    ## If not, set to half of the number of non-targeting elements 
-    if num_pseudogenes is None:
-        num_pseudogenes = len(adata.var[adata.var.targetType.eq(ctrl_label)]) // 2
-    # Get non-targeting elements
-    ctrl_elements = adata.var[adata.var.targetType.eq(ctrl_label)].index
-    adata.var['pseudoLabel'] = ''
-    # Check if there are more than 1 non-targeting elements to label as pseudogenes
-    if len(ctrl_elements) / 2 <= num_pseudogenes:
-        # raise error if `num_pseudogenes` is greater than (total number of non-targeting elements) / 2
-        raise TypeError(
-            "Define `num_pseudogenes` to be less than (total number of non-targeting elements) / 2"
-        )
-    else:
-        # randomly select `num` non-targeting elements
-        while len(ctrl_elements) > num_pseudogenes:
-            # randomly select `num` non-targeting elements
-            pseudo_elements = np.random.choice(ctrl_elements, num_pseudogenes, replace=False)
-            # generate new labels
-            pseudo_labels = [f'pseudo_{i}' for i in range(num_pseudogenes)]
-            # update adata.var
-            adata.var.loc[pseudo_elements, 'pseudoLabel'] = pseudo_labels
-            # remove selected elements from ctrl_elements
-            ctrl_elements = ctrl_elements.drop(pseudo_elements)
-
-        # label remaining non-targeting elements as pseudogenes
-        adata.var.loc[adata.var.targetType.eq('gene'), 'pseudoLabel'] = 'gene'
-        adata.var.loc[adata.var.pseudoLabel.eq(''), 'pseudoLabel'] = np.nan
-
-# def addPseudoCount():
-    # # pseudocount
-    # if pseudocountBehavior == 'default' or pseudocountBehavior == 'zeros only':
-    #     def defaultBehavior(row):
-    #         return row if min(
-    #             row) != 0 else row + pseudocountValue
-    #
-    #     combinedCountsPseudo = combinedCounts.apply(defaultBehavior, axis=1)
-    # elif pseudocountBehavior == 'all values':
-    #     combinedCountsPseudo = combinedCounts.apply(
-    #         lambda row: row + pseudocountValue, axis=1)
-    # elif pseudocountBehavior == 'filter out':
-    #     combinedCountsPseudo = combinedCounts.copy()
-    #     zeroRows = combinedCounts.apply(lambda row: min(row) <= 0, axis=1)
-    #     combinedCountsPseudo.loc[zeroRows, :] = np.nan
-    # else:
-    #     raise ValueError(
-    #         'Pseudocount behavior not recognized or not implemented')
-
```

## screenpro/phenostat.py

```diff
@@ -20,14 +20,19 @@
     Returns:
         np.array: array of p-values
     """
     # calculate p-values
     if test == 'MW':
         # run Mann-Whitney U rank test
         raise ValueError('Mann-Whitney U rank test not implemented')
+    
+    elif test == 'KS':
+        # run Kolmorogov-Smirnov test
+        raise ValueError('Kolmorogov-Smirnov test not implemented')
+    
     elif test == 'ttest':
         # run ttest
         if level == 'col':
             p_value = ttest_rel(y, x, axis=1)[1]
         elif level == 'row':
             p_value = ttest_rel(y, x, axis=0)[1]
         elif level == 'all':
```

## screenpro/utils.py

```diff
@@ -44,15 +44,15 @@
     print(
         f"{n_removed} variables with less than {minimum_reads} reads in {filter_type} replicates / experiment"
     )
 
     adata.var['low_count'] = ~adata.var.index.isin(out.var.index.to_list())
 
 
-def ann_score_df(df_in, up_hit='resistance_hit', down_hit='sensitivity_hit', ctrl_label='non-targeting', threshold=10):
+def ann_score_df(df_in, up_hit='resistance_hit', down_hit='sensitivity_hit', ctrl_label='negCtrl', threshold=10):
     """
     Annotate score dataframe with hit labels using given `threshold`
     (i.e. `score/pseudo_sd * -np.log10(pvalue) >= threshold`).
 
     Parameters:
         df_in (pd.DataFrame): score dataframe
         up_hit (str): up hit label
```

## screenpro/ngs/counter.py

```diff
@@ -26,14 +26,22 @@
         '''
         if self.cas_type == 'cas9':
             library = load_cas9_sgRNA_library(library_path, library_type=self.library_type, sep=sep, index_col=index_col, protospacer_length=protospacer_length, verbose=verbose)
 
         elif self.cas_type == 'cas12':
             raise NotImplementedError("Cas12 library is not yet implemented.")
         
+        # Check if the library has duplicate sequences and remove them
+        if library.duplicated('sequence').any():
+            shape_before_dedup = library.shape[0]
+            library = library.drop_duplicates(subset='sequence', keep='first')
+            shape_after_dedup = library.shape[0]
+            if verbose:
+                print(f"Warning: {shape_before_dedup - shape_after_dedup} duplicate sgRNA sequences found and removed.")
+
         # covert to polar DataFrame
         library = pl.from_pandas(library)
 
         self.library = library
         
     def _get_sgRNA_table(self):
```

## Comparing `ScreenPro2-0.3.1.dist-info/LICENSE` & `ScreenPro2-0.3.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `ScreenPro2-0.3.1.dist-info/METADATA` & `ScreenPro2-0.3.2.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: ScreenPro2
-Version: 0.3.1
+Version: 0.3.2
 Summary: Flexible analysis of high-content CRISPR screening
 Home-page: https://github.com/ArcInstitute/ScreenPro2
 Author: Abe Arab
 Author-email: abea@arcinstitute.org
 Maintainer: Abe Arab
 Maintainer-email: abea@arcinstitute.org
 License: MIT License
```

## Comparing `ScreenPro2-0.3.1.dist-info/RECORD` & `ScreenPro2-0.3.2.dist-info/RECORD`

 * *Files 26% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-screenpro/__init__.py,sha256=O_3IxIwilb-Vs8qAY6Hw5NBswra0ZFvQ6AVKRKieU88,292
+screenpro/__init__.py,sha256=Hd3FARlQ1Q0owioSgIPMKnp6SzNM7jIgXANxDdGO8Yo,292
 screenpro/__main__.py,sha256=vBQ82334kX06ImDbFlPFgiBRiLIinwNk3z8Khs6hd74,31
-screenpro/assays.py,sha256=1U1uQQemync_09kCFuvqfY7YBCsAJXNDmvhExqX36ws,8370
+screenpro/assays.py,sha256=aEFmXXZ7K21PHih0hQp5eMB7URhwejceGZUfeVsfeKA,9351
 screenpro/load.py,sha256=McWwXrSAVsGmJJNEh5Y36laSiy1y02nxn7yGaR5D6ew,7406
 screenpro/main.py,sha256=gtda5LEz3-qPBOdGZlLcAOvHxyPHp0hqUWHiDXMrYaQ,5343
-screenpro/phenoscore.py,sha256=FiypQeruYYR1yP21ldTWl84b-PAzMqmyyiNKy6NANqw,16261
-screenpro/phenostat.py,sha256=HoyHL9MB359a4Cbh0zVve5DwffhGwuwNMnvcMultq-w,1694
+screenpro/phenoscore.py,sha256=Kjhi-h0FxwA1gxVz4mCvBTLhDfiIFjK_PmZrLrRB05k,16444
+screenpro/phenostat.py,sha256=QINZMVMlI8RX3sfr8EZqhS3mXKIm9pnKzvPmz8CBVbU,1833
 screenpro/plotting.py,sha256=2NEWnHZhGtSqEDWndK53BpFHFY7ewKedS9R2V9_QJmo,7040
-screenpro/utils.py,sha256=C_NJ7lYqk5jrONeSBMJY9uVfQaEyrhvufzqoEaVXM38,3179
+screenpro/utils.py,sha256=LTXq8Lu8b-zIrOkEQ6UwOwSFQM-_wMOZTRHPzs95bp0,3173
 screenpro/ngs/__init__.py,sha256=a66lnaCrsoIrMlz4dMYj9jwp5cBjNLXs7fBruHDujHE,1731
 screenpro/ngs/cas12.py,sha256=kqJUIwKlDse6QPGqZryIRfwexvivhTJvGsN9v5SmdKo,6944
 screenpro/ngs/cas9.py,sha256=7hyb020LwK_FbNfb_quQvFyUjcBOnJaKmXMWX83VgzE,6808
-screenpro/ngs/counter.py,sha256=ez_GvPiBB1vnLS7TH7a_Q-L_yXHcCFSiPDLJkYh8cW8,14980
+screenpro/ngs/counter.py,sha256=1jRyb-sywECmt2qT-r0f9Kv27ynOi6EVJwOoBUc2Cqc,15424
 screenpro/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 screenpro/tests/test_fastq2count.py,sha256=odxZO2k2UgVT7aXIGiWAwDgxtTnLxZsXqZPOi9AN5Hg,821
 screenpro/tests/test_phenoscore.py,sha256=CMGeO6-b4SzvnMHTUvWuSAOSbcKn9zAhJRyQf65DTug,1791
-ScreenPro2-0.3.1.dist-info/LICENSE,sha256=FPCrnT6b2kagxfQA9wg0diTKFQNu3DFK79GiYrv5dKQ,1187
-ScreenPro2-0.3.1.dist-info/METADATA,sha256=IGs9axJS39EjhgDnegTCeHpLZmqKEfZdoGI3KnMVU4U,13013
-ScreenPro2-0.3.1.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
-ScreenPro2-0.3.1.dist-info/entry_points.txt,sha256=_xe3Ghe-MaVMaDlSDWXP9LcNmvDmn9-bACkNmaOscYU,50
-ScreenPro2-0.3.1.dist-info/top_level.txt,sha256=uOEhN69bjK8D-lUo9aFehqGZQiGp8ouTSdzTDvZ4aek,10
-ScreenPro2-0.3.1.dist-info/RECORD,,
+ScreenPro2-0.3.2.dist-info/LICENSE,sha256=FPCrnT6b2kagxfQA9wg0diTKFQNu3DFK79GiYrv5dKQ,1187
+ScreenPro2-0.3.2.dist-info/METADATA,sha256=00sixgG7uaZ7rqlk3whYIanKgndEumsQ_ZeZ3BfTxJ8,13013
+ScreenPro2-0.3.2.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
+ScreenPro2-0.3.2.dist-info/entry_points.txt,sha256=_xe3Ghe-MaVMaDlSDWXP9LcNmvDmn9-bACkNmaOscYU,50
+ScreenPro2-0.3.2.dist-info/top_level.txt,sha256=uOEhN69bjK8D-lUo9aFehqGZQiGp8ouTSdzTDvZ4aek,10
+ScreenPro2-0.3.2.dist-info/RECORD,,
```

